% !TeX program = XeLaTeX
---
title: "Εργασία 1"
author: "Θωμάς Παππάς"
date: "26/10/2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::read_chunk('R/ergasia1.R')
```

# Άσκηση 1


```{r ask1_nnk}
```

# Άσκηση 2

Αρχικά φορτώνουμε τα δεδομένα.
```{r}
ozone = read.csv("data/ozone.data", sep="\t")
```

## Βήμα 1

Πρώτα δημιουργούμε μια τυχαία μετάθεση των αριθμών 1-111 (μέχρι και τον συνολικό
αριθμό των γραμμών των δεδομένων) έτσι ώστε να πάρουμε μια τυχαία διαμέριση.
```{r}
size = nrow(ozone)
partition_index = 80

sample_indexes = sample(size)
train_set = ozone[sample_indexes[1:partition_index],]
test_set = ozone[sample_indexes[(partition_index+1):size],]
```

## Βήμα 2

Στη συνέχεια χωρίζουμε το κάθε dataset στις ανεξάρτητες και εξαρτημένες
μεταβλητές αντίστοιχα
```{r}
independent_vars = c("radiation", "temperature", "wind")
X_train = train_set[, independent_vars]
X_test = test_set[, independent_vars]
y_train = train_set$ozone
y_test = test_set$ozone
```

και ορίζουμε συνάρτηση που να υπολογίζει το μέσο τετραγωνικό σφάλμα.
```{r ask1_epek}
```

και έτσι τώρα μπορούμε για ολα τα ζητούμενα k να εφαρμόσουμε το nnk και να
υπολογίσουμε το μέσο τετραγωνικό σφάλμα της πρόβλεψής μας.
```{r}
k_values = c(1, 2, 5, 10, 15, 20, 30, 40)
epe_values = rep(0, length(k_values))

for (i in 1:length(k_values))
{
  y_pred = apply(X_test, 1, nnk, x=X_train, y=y_train, k=k_values[i])
  epe_values[i] = epe(y_pred, y_test)
}
print(epe_values)
```

## Βήμα 3

Τέλος το γράφημα του μέσου σφάλματος πρόβλεψης ως συνάρτησης του k.
```{r}
plot(k_values, epe_values)
```

όπου παρατηρούμε ότι όσο ανεβαίνει το k και άρα το bias μεγαλώνει τότε
το variance πέφτει.

# Άσκηση 3

Θα χρησιμοποιήσουμε τη μέθοδο "knn" από το πακέτο "neighbr".
Σε αυτή τη μέθοδο το training set χρειάζεται να έχει και την target στήλη ενώ
το test set όχι.
Οπότε για τα ίδια k επαναλαμβάνουμε
```{r}
epe_values_pack = rep(0, length(k_values))
for (i in 1:length(k_values))
{
  y_pred_pack = neighbr::knn(
    train_set=train_set,
    test_set=X_test,
    k=k_values[i],
    comparison_measure="euclidean",
    continuous_target="ozone"
  )
  # Now the predictions are in the "test_set_scores" column which is a
  # data frame with the numbers in the "continuous_target" column.
  y_pred_pack = y_pred_pack$test_set_scores$continuous_target
  epe_values_pack[i] = epe(y_pred_pack, y_test)
}
print(epe_values_pack)
```

και τέλος κατασκευάζουμε και το γράφημα
```{r}
plot(k_values, epe_values_pack)
```
